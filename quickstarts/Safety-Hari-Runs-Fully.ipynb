{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# Gemini API: Safety Quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXQ3OwKIa-O"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOxMUKTxR-_j"
      },
      "source": [
        "The Gemini API has adjustable safety settings. This notebook walks you through how to use them. You'll write a prompt that's blocked, see the reason why, and then adjust the filters to unblock it.\n",
        "\n",
        "Safety is an important topic, and you can learn more with the links at the end of this notebook. Here, you will focus on the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9OEoeosRTv-5"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai # Install the Python SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VAUtJubX7MG"
      },
      "source": [
        "## Import the Gemini python SDK\n",
        "\n",
        "Once the kernel is restarted, you can import the Gemini SDK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TS9l5igubpHO"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHYFrFPjSGNq"
      },
      "source": [
        "## Set up your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ab9ASynfcIZn"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfoK3I3hu6V"
      },
      "source": [
        "## Send your prompt request to Gemini\n",
        "\n",
        "Pick the prompt you want to use to test the safety filters settings. An examples could be `Write a list of 5 very rude things that I might say to the universe after stubbing my toe in the dark` which was previously tested and trigger the `HARM_CATEGORY_HARASSMENT` and `HARM_CATEGORY_DANGEROUS_CONTENT` categories.\n",
        "\n",
        "The result returned by the [Model.generate_content](https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content) method is a [genai.protos.GenerateContentResponse](https://ai.google.dev/api/python/google/generativeai/types/GenerateContentResponse)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2bcfnGEviwTI"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "unsafe_prompt = \"I support Martians Soccer Club and I think Jupiterians Football Club sucks! Write a ironic phrase about them.\"\n",
        "response = model.generate_content(unsafe_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR_2A_sxk8sK"
      },
      "source": [
        "This response object gives you safety feedback about the candidate answers Gemini generates to you.\n",
        "\n",
        "For each candidate answer you need to check `response.candidates.finish_reason`.\n",
        "\n",
        "As you can find on the [Gemini API safety filters documentation](https://ai.google.dev/gemini-api/docs/safety-settings#safety-feedback):\n",
        "- if the `candidate.finish_reason` is `FinishReason.STOP` means that your generation request ran successfully\n",
        "- if the `candidate.finish_reason` is `FinishReason.SAFETY` means that your generation request was blocked by safety reasons. It also means that the `response.text` structure will be empty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8887de812dc0",
        "outputId": "8d1d948f-d06b-4623-a765-ef70d83e500b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FinishReason.SAFETY\n"
          ]
        }
      ],
      "source": [
        "print(response.candidates[0].finish_reason)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBdqPso3kamW"
      },
      "source": [
        "If the `finish_reason` is `FinishReason.SAFETY` you can check which filter caused the block checking the `safety_ratings` list for the candidate answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "he-OfzBbhACQ",
        "outputId": "fa9d7754-893f-4069-9869-55f5f316585e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_HATE_SPEECH\n",
            "probability: LOW\n",
            ", category: HARM_CATEGORY_HARASSMENT\n",
            "probability: MEDIUM\n",
            ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "probability: NEGLIGIBLE\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(response.candidates[0].safety_ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9-SdzjbxWXT"
      },
      "source": [
        "As the request was blocked by the safety filters, the `response.text` field will be empty (as nothing as generated by the model):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "L1Da4cJ3xej3",
        "outputId": "85efde07-8d7b-4a4a-a5d0-491e144ca8e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No information generated by the model.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    print(response.text)\n",
        "except:\n",
        "    print(\"No information generated by the model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4672af98ac57"
      },
      "source": [
        "## Customizing safety settings\n",
        "\n",
        "Depending on the scenario you are working with, it may be necessary to customize the safety filters behaviors to allow a certain degree of unsafety results.\n",
        "\n",
        "To make this customization you must define a `safety_settings` dictionary as part of your `model.generate_content()` request. In the example below, all the filters are being set to do not block contents.\n",
        "\n",
        "**Important:** To guarantee the Google commitment with the Responsible AI development and its [AI Principles](https://ai.google/responsibility/principles/), for some prompts Gemini will avoid generating the results even if you set all the filters to none."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "338fb9a6af78"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(\n",
        "    unsafe_prompt,\n",
        "    safety_settings={\n",
        "        'HATE': 'BLOCK_NONE',\n",
        "        'HARASSMENT': 'BLOCK_NONE',\n",
        "        'SEXUAL' : 'BLOCK_NONE',\n",
        "        'DANGEROUS' : 'BLOCK_NONE'\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "564K7R8rwWhs"
      },
      "source": [
        "Checking again the `candidate.finish_reason` information, if the request was not too unsafe, it must show now the value as `FinishReason.STOP` which means that the request was successfully processed by Gemini."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LazB08GBpc1w",
        "outputId": "c689fe4d-bb2d-4ca6-a919-3b9aadceaa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FinishReason.STOP\n"
          ]
        }
      ],
      "source": [
        "print(response.candidates[0].finish_reason)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86c560e0a641"
      },
      "source": [
        "Since the request was successfully generated, you can check the result on the `response.text`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0c2847c49262",
        "outputId": "d73fdd42-6548-45b9-9df3-3853d5b60570",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Jupiterians Football Club: Proof that even on a gas giant, you can still be a flat tire.\" \n",
            "\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    print(response.text)\n",
        "except:\n",
        "    print(\"No information generated by the model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47298a4eef40"
      },
      "source": [
        "And if you check the safety filters ratings, as you set all filters to be ignored, no filtering category was trigerred:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "028febe8df68",
        "outputId": "db05d2a7-35dd-4ce1-d9c5-47a94b8074a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_HATE_SPEECH\n",
            "probability: LOW\n",
            ", category: HARM_CATEGORY_HARASSMENT\n",
            "probability: MEDIUM\n",
            ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "probability: NEGLIGIBLE\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(response.candidates[0].safety_ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1UdbxVt3ysY"
      },
      "source": [
        "## Learning more\n",
        "\n",
        "Learn more with these articles on [safety guidance](https://ai.google.dev/docs/safety_guidance) and [safety settings](https://ai.google.dev/docs/safety_setting_gemini).\n",
        "\n",
        "## Useful API references\n",
        "\n",
        "There are 4 configurable safety settings for the Gemini API:\n",
        "* `HARM_CATEGORY_DANGEROUS_CONTENT`\n",
        "* `HARM_CATEGORY_HARASSMENT`\n",
        "* `HARM_CATEGORY_SEXUALLY_EXPLICIT`\n",
        "* `HARM_CATEGORY_HATE_SPEECH`\n",
        "\n",
        "You can refer to the safety settings using either their full name, or the aliases like `DANGEROUS` used in the Python code above.\n",
        "\n",
        "Safety settings can be set in the [genai.GenerativeModel](https://ai.google.dev/api/python/google/generativeai/GenerativeModel) constructor.\n",
        "\n",
        "* They can also be passed on each request to [GenerativeModel.generate_content](https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content) or [ChatSession.send_message](https://ai.google.dev/api/python/google/generativeai/ChatSession?hl=en#send_message).\n",
        "\n",
        "- The [genai.protos.GenerateContentResponse](https://ai.google.dev/api/python/google/generativeai/protos/GenerateContentResponse) returns [SafetyRatings](https://ai.google.dev/api/python/google/generativeai/protos/SafetyRating) for the prompt in the [GenerateContentResponse.prompt_feedback](https://ai.google.dev/api/python/google/generativeai/protos/GenerateContentResponse/PromptFeedback), and for each [Candidate](https://ai.google.dev/api/python/google/generativeai/protos/Candidate) in the `safety_ratings` attribute.\n",
        "\n",
        "- A [genai.protos.SafetySetting](https://ai.google.dev/api/python/google/generativeai/protos/SafetySetting)  contains: [genai.protos.HarmCategory](https://ai.google.dev/api/python/google/generativeai/protos/HarmCategory) and a [genai.protos.HarmBlockThreshold](https://ai.google.dev/api/python/google/generativeai/types/HarmBlockThreshold)\n",
        "\n",
        "- A [genai.protos.SafetyRating](https://ai.google.dev/api/python/google/generativeai/protos/SafetyRating) contains a [HarmCategory](https://ai.google.dev/api/python/google/generativeai/protos/HarmCategory) and a [HarmProbability](https://ai.google.dev/api/python/google/generativeai/types/HarmProbability)\n",
        "\n",
        "The [genai.protos.HarmCategory](https://ai.google.dev/api/python/google/generativeai/protos/HarmCategory) enum includes both the categories for PaLM and Gemini models.\n",
        "\n",
        "- When specifying enum values the SDK will accept the enum values themselves, or their integer or string representations.\n",
        "\n",
        "- The SDK will also accept abbreviated string representations: `[\"HARM_CATEGORY_DANGEROUS_CONTENT\", \"DANGEROUS_CONTENT\", \"DANGEROUS\"]` are all valid. Strings are case insensitive."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content('Teach me about how an LLM works')\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "fx1F1nGLr77r",
        "outputId": "dfce2dcf-8eee-4395-d622-a963d18bd603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## How LLMs Work: A Simplified Explanation\n",
            "\n",
            "Large Language Models (LLMs) are complex, but their core functioning can be understood with a simplified explanation:\n",
            "\n",
            "**1. Training:**\n",
            "\n",
            "* **Data:** LLMs are trained on massive datasets of text and code, containing everything from books and articles to social media posts and code repositories.\n",
            "* **Neural Networks:** LLMs use a type of artificial neural network called a transformer, which excels at understanding relationships between words in a sentence.\n",
            "* **Learning:** During training, the LLM learns to predict the next word in a sequence based on the preceding words. This process allows the model to understand grammar, semantics, and the nuances of language.\n",
            "\n",
            "**2. Understanding Input:**\n",
            "\n",
            "* **Tokenization:** When you provide input, the LLM first breaks it down into individual tokens (words or parts of words).\n",
            "* **Embedding:** Each token is then represented by a vector, a set of numbers that captures its meaning and relationship to other words.\n",
            "\n",
            "**3. Generating Output:**\n",
            "\n",
            "* **Probability:** The LLM calculates the probability of different words appearing next in the sequence.\n",
            "* **Output:** Based on these probabilities, the model generates the most likely output, producing text that is coherent and relevant to the input.\n",
            "\n",
            "**Here's an analogy:** Imagine you're building a model of a city. You start with a massive pile of building blocks representing words. You train the model by figuring out how to stack these blocks together to form recognizable structures (sentences). When you give the model a starting point (input), it uses its learned knowledge to predict the next blocks to add (output) and continue building the city.\n",
            "\n",
            "**Key points to remember:**\n",
            "\n",
            "* LLMs are trained on vast amounts of data, enabling them to learn and generate human-like text.\n",
            "* They understand context and relationships between words, allowing them to generate coherent and meaningful responses.\n",
            "* They are probabilistic, meaning their output is based on calculated probabilities, not deterministic rules.\n",
            "\n",
            "**Simplified Analogy:** Think of LLMs as sophisticated auto-complete systems that learn from massive amounts of text and predict the most likely words to come next, resulting in coherent and relevant responses.\n",
            "\n",
            "**Note:** This is a simplified explanation. The actual workings of LLMs are much more complex and involve advanced techniques like attention mechanisms and self-supervised learning.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content('How big is softmax vector of Gemini which generate the token at last step of the the generation')\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "W_RcWDa3sZUg",
        "outputId": "d1dbb151-777c-41c3-c8ca-31772e548d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unfortunately, there is no publicly available information on the exact size of the softmax vector used by Gemini for its final token generation.  Here's why:\n",
            "\n",
            "* **Proprietary Information:** Google keeps the inner workings of Gemini, including details like the softmax vector size, as proprietary information.\n",
            "* **Model Complexity:** Gemini is a highly complex model, and the size of the softmax vector likely depends on factors like:\n",
            "    * The number of tokens in its vocabulary.\n",
            "    * The specific architecture of the model (e.g., number of layers, hidden size).\n",
            "    * Any special adaptations made to the model's output. \n",
            "\n",
            "**What we can infer:**\n",
            "\n",
            "* **Large Vocabulary:** Since Gemini is a powerful language model, it likely has a large vocabulary, potentially containing tens of thousands or even millions of tokens.  This would imply a large softmax vector.\n",
            "* **Dynamic Sizing:**  It's possible that the model doesn't use a fixed-size softmax vector but dynamically adjusts its size based on the context of the generated text.\n",
            "\n",
            "**Instead of the exact size, consider these factors about softmax vectors:**\n",
            "\n",
            "* **Probability Distribution:** The softmax vector represents a probability distribution over all possible tokens in the model's vocabulary. \n",
            "* **Highest Probability:** The token with the highest probability in the softmax vector is chosen as the next token in the generated text. \n",
            "\n",
            "**In summary, while we don't know the exact size of the softmax vector used by Gemini, it is likely to be very large due to the model's complex nature and large vocabulary.** \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content('How all possible tokens in the llama3, which are used by softmax layer to generate text')\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "oQskcGSktDAf",
        "outputId": "3775c338-b3b6-442d-d5a1-551697932f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It's impossible to list *all* possible tokens used by a language model like Llama 3. Here's why:\n",
            "\n",
            "* **Vast Number:** The vocabulary size of a large language model can be enormous, potentially in the millions or even billions of tokens. \n",
            "* **Dynamic Vocabulary:** Some models don't have a fixed, pre-defined vocabulary. They may learn new tokens on the fly based on the data they are trained on.\n",
            "* **Tokenization:** Tokens aren't always single words. They can be subword units (like \"un-\", \"ing\", \"able\"), characters, or even combinations of these.\n",
            "\n",
            "**What we can tell you:**\n",
            "\n",
            "* **Tokenization:** Llama 3 likely uses a tokenizer like BPE (Byte Pair Encoding) to break down text into smaller units. This allows the model to handle a wider range of words and phrases, including those not seen during training.\n",
            "* **Softmax Layer:** The softmax layer in a language model takes the output of the model's hidden layers and converts it into a probability distribution over all possible tokens. This distribution represents the likelihood of each token being the next one in the sequence.\n",
            "* **Vocabulary Size:** While we don't know the exact number, Llama 3 likely has a large vocabulary, which is essential for its ability to generate diverse and coherent text.\n",
            "\n",
            "**Instead of a list, here are ways to understand the tokenization process:**\n",
            "\n",
            "1. **Check the Model's Documentation:** If available, Llama 3's documentation might provide information about its tokenization method and vocabulary size.\n",
            "2. **Explore Tokenizers:** Familiarize yourself with different tokenization techniques like BPE, WordPiece, and SentencePiece. \n",
            "3. **Experiment:** Use a library like Hugging Face's Transformers to experiment with tokenization and see how it works on various text samples.\n",
            "\n",
            "Remember, understanding the mechanics of tokenization is more important than having a complete list of tokens, as it helps you grasp how language models process and generate text. \n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Safety.ipynb",
      "provenance": []
    },
    "google": {
      "image_path": "/static/site-assets/images/docs/logo-python.svg",
      "keywords": [
        "examples",
        "gemini",
        "beginner",
        "googleai",
        "quickstart",
        "python",
        "text",
        "chat",
        "vision",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}